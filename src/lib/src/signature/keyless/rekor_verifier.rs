//! Rekor Transparency Log Verification
//!
//! This module implements cryptographic verification of Rekor log entries:
//! 1. Signed Entry Timestamp (SET) verification
//! 2. Merkle tree inclusion proof verification
//!
//! # Security Model
//!
//! Rekor entries are verified using:
//! - **SET (Signed Entry Timestamp)**: ECDSA P-256 signature over entry metadata
//! - **Inclusion Proof**: RFC 6962 Merkle tree proof
//! - **Trust Anchors**: Rekor public keys from Sigstore TUF repository
//!
//! The SET proves that Rekor accepted and timestamped the entry.
//! The inclusion proof proves that the entry exists in the transparency log.

use crate::error::WSError;
use crate::signature::keyless::{merkle, RekorEntry};
use base64::{engine::general_purpose::STANDARD as BASE64, Engine};
use p256::ecdsa::{Signature, VerifyingKey, signature::DigestVerifier};
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};

/// Trusted root configuration for Rekor transparency logs
#[derive(Debug, Serialize, Deserialize)]
struct TrustedRoot {
    tlogs: Vec<TransparencyLog>,
}

/// Transparency log configuration from TUF
#[derive(Debug, Serialize, Deserialize)]
struct TransparencyLog {
    #[serde(rename = "baseUrl")]
    base_url: String,
    #[serde(rename = "hashAlgorithm")]
    hash_algorithm: String,
    #[serde(rename = "publicKey")]
    public_key: PublicKeyInfo,
    #[serde(rename = "logId")]
    log_id: LogId,
}

#[derive(Debug, Serialize, Deserialize)]
struct PublicKeyInfo {
    #[serde(rename = "rawBytes")]
    raw_bytes: String, // Base64-encoded
    #[serde(rename = "keyDetails")]
    key_details: String,
    #[serde(rename = "validFor")]
    valid_for: ValidFor,
}

#[derive(Debug, Serialize, Deserialize)]
struct LogId {
    #[serde(rename = "keyId")]
    key_id: String,
}

#[derive(Debug, Serialize, Deserialize)]
struct ValidFor {
    start: String,
}

/// Rekor inclusion proof structure (deserialized from JSON)
#[derive(Debug, Deserialize)]
pub struct InclusionProof {
    pub hashes: Vec<String>,
    #[serde(rename = "logIndex")]
    pub log_index: u64,
    #[serde(rename = "rootHash")]
    pub root_hash: String,
    #[serde(rename = "treeSize")]
    pub tree_size: u64,
    #[serde(default)]
    pub checkpoint: Option<String>,
}

/// Checkpoint (Signed Tree Head) - a cryptographically signed commitment to a tree state
///
/// Format:
/// ```text
/// <origin>
/// <tree_size>
/// <root_hash_base64>
/// [<other_content>]...
///
/// ‚Äî <name> <fingerprint+signature_base64>
/// ```
#[derive(Debug)]
pub struct Checkpoint {
    pub note: CheckpointNote,
    pub signature: CheckpointSignature,
}

/// The unsigned portion of a checkpoint
#[derive(Debug)]
pub struct CheckpointNote {
    /// Origin identifier (e.g., "rekor.sigstore.dev - 1193050959916656506")
    pub origin: String,
    /// Tree size (number of entries)
    pub size: u64,
    /// Root hash (32 bytes)
    pub hash: [u8; 32],
    /// Optional additional content lines
    pub other_content: Vec<String>,
}

/// Checkpoint signature
#[derive(Debug)]
pub struct CheckpointSignature {
    /// Name/identity of signer
    pub name: String,
    /// First 4 bytes of SHA-256(PKIX public key)
    pub key_fingerprint: [u8; 4],
    /// Raw signature bytes (ECDSA P-256)
    pub raw: Vec<u8>,
}

impl Checkpoint {
    /// Parse a checkpoint from string format
    ///
    /// Expected format:
    /// ```text
    /// <origin>\n
    /// <size>\n
    /// <hash_base64>\n
    /// [<other_content>\n]...
    /// \n
    /// ‚Äî <name> <fingerprint+signature_base64>\n
    /// ```
    pub fn decode(s: &str) -> Result<Self, WSError> {
        let s = s.trim_matches('"').trim_matches('\n');

        // Split into note and signature parts (separated by blank line)
        let parts: Vec<&str> = s.split("\n\n").collect();
        if parts.len() != 2 {
            return Err(WSError::RekorError(
                "Invalid checkpoint format: expected note and signature separated by blank line".to_string()
            ));
        }

        let note = CheckpointNote::decode(parts[0])?;
        let signature = CheckpointSignature::decode(parts[1])?;

        Ok(Checkpoint { note, signature })
    }
}

impl CheckpointNote {
    /// Parse checkpoint note from string
    fn decode(s: &str) -> Result<Self, WSError> {
        let lines: Vec<&str> = s.split('\n').collect();
        if lines.len() < 3 {
            return Err(WSError::RekorError(
                "Invalid checkpoint note: expected at least 3 lines".to_string()
            ));
        }

        let origin = lines[0].to_string();
        if origin.is_empty() {
            return Err(WSError::RekorError(
                "Invalid checkpoint: empty origin".to_string()
            ));
        }

        let size: u64 = lines[1].parse()
            .map_err(|_| WSError::RekorError("Invalid checkpoint: size not a valid u64".to_string()))?;

        let hash_bytes = BASE64.decode(lines[2])
            .map_err(|e| WSError::RekorError(format!("Invalid checkpoint: failed to decode hash: {}", e)))?;

        if hash_bytes.len() != 32 {
            return Err(WSError::RekorError(format!(
                "Invalid checkpoint: hash must be 32 bytes, got {}",
                hash_bytes.len()
            )));
        }

        let mut hash = [0u8; 32];
        hash.copy_from_slice(&hash_bytes);

        // Collect any additional content lines (excluding empty lines)
        let other_content: Vec<String> = lines[3..]
            .iter()
            .filter(|line| !line.is_empty())
            .map(|line| line.to_string())
            .collect();

        Ok(CheckpointNote {
            origin,
            size,
            hash,
            other_content,
        })
    }

    /// Marshal checkpoint note to string (for signature verification)
    ///
    /// This is the exact bytes that get signed.
    fn marshal(&self) -> String {
        let hash_b64 = BASE64.encode(&self.hash);
        let mut result = format!("{}\n{}\n{}\n", self.origin, self.size, hash_b64);

        for line in &self.other_content {
            result.push_str(line);
            result.push('\n');
        }

        result
    }
}

impl CheckpointSignature {
    /// Parse checkpoint signature from string
    ///
    /// Expected format: `‚Äî <name> <fingerprint+signature_base64>`
    fn decode(s: &str) -> Result<Self, WSError> {
        let s = s.trim();

        // Split by whitespace
        let parts: Vec<&str> = s.split_whitespace().collect();
        if parts.len() != 3 {
            return Err(WSError::RekorError(format!(
                "Invalid checkpoint signature format: expected 3 parts, got {}",
                parts.len()
            )));
        }

        // Verify em dash marker
        if parts[0] != "‚Äî" {
            return Err(WSError::RekorError(
                "Invalid checkpoint signature: expected em dash (‚Äî)".to_string()
            ));
        }

        let name = parts[1].to_string();

        // Decode base64 signature (fingerprint + raw signature)
        let sig_bytes = BASE64.decode(parts[2])
            .map_err(|e| WSError::RekorError(format!("Failed to decode checkpoint signature: {}", e)))?;

        if sig_bytes.len() < 5 {
            return Err(WSError::RekorError(
                "Checkpoint signature too short (need at least 5 bytes)".to_string()
            ));
        }

        // First 4 bytes are the key fingerprint
        let mut key_fingerprint = [0u8; 4];
        key_fingerprint.copy_from_slice(&sig_bytes[0..4]);

        // Remaining bytes are the raw signature
        let raw = sig_bytes[4..].to_vec();

        Ok(CheckpointSignature {
            name,
            key_fingerprint,
            raw,
        })
    }
}

/// Pool of Rekor public keys for verification
pub struct RekorKeyring {
    /// ECDSA P-256 verifying keys indexed by log ID
    keys: Vec<(String, VerifyingKey)>,
}

impl RekorKeyring {
    /// Extract tree ID from a Rekor UUID
    ///
    /// UUID format: <tree_id (16 hex chars)><leaf_hash (64 hex chars)>
    /// Total length: 80 characters
    ///
    /// Returns the tree ID as a decimal string for comparison with checkpoint origin
    fn extract_tree_id_from_uuid(uuid: &str) -> Result<String, WSError> {
        if uuid.len() != 80 {
            return Err(WSError::RekorError(format!(
                "Invalid UUID length: expected 80, got {}",
                uuid.len()
            )));
        }

        // First 16 characters are the tree ID (hex)
        let tree_id_hex = &uuid[0..16];

        // Convert hex to u64 (tree ID is 8 bytes)
        let tree_id = u64::from_str_radix(tree_id_hex, 16)
            .map_err(|e| WSError::RekorError(format!("Failed to parse tree ID from UUID: {}", e)))?;

        // Return as decimal string for comparison with checkpoint origin
        Ok(tree_id.to_string())
    }

    /// Validate checkpoint origin matches expected values
    ///
    /// Checks:
    /// 1. Origin format is "<hostname> - <tree_id>"
    /// 2. Hostname is "rekor.sigstore.dev" (expected Rekor production)
    /// 3. Tree ID matches the tree ID in the entry's UUID
    ///
    /// This prevents accepting checkpoints from wrong logs or shards.
    fn validate_checkpoint_origin(checkpoint: &Checkpoint, entry_uuid: &str) -> Result<(), WSError> {
        // Parse origin: should be "<hostname> - <tree_id>"
        let parts: Vec<&str> = checkpoint.note.origin.split(" - ").collect();
        if parts.len() != 2 {
            return Err(WSError::RekorError(format!(
                "Invalid checkpoint origin format: expected '<hostname> - <tree_id>', got '{}'",
                checkpoint.note.origin
            )));
        }

        let hostname = parts[0];
        let checkpoint_tree_id = parts[1];

        // SECURITY: Validate hostname matches expected production Rekor
        // This prevents accepting checkpoints from malicious or test logs
        if hostname != "rekor.sigstore.dev" {
            return Err(WSError::RekorError(format!(
                "Unexpected checkpoint origin hostname: expected 'rekor.sigstore.dev', got '{}'",
                hostname
            )));
        }

        // SECURITY: Validate tree ID matches the entry's UUID
        // This prevents cross-shard attacks where a checkpoint from one shard
        // is used to verify an entry from a different shard
        let entry_tree_id = Self::extract_tree_id_from_uuid(entry_uuid)?;
        if checkpoint_tree_id != entry_tree_id {
            return Err(WSError::RekorError(format!(
                "Checkpoint tree ID mismatch: checkpoint has '{}', but entry UUID has '{}'",
                checkpoint_tree_id, entry_tree_id
            )));
        }

        log::debug!(
            "Checkpoint origin validated: hostname={}, tree_id={}",
            hostname,
            checkpoint_tree_id
        );
        Ok(())
    }

    /// Compute the key fingerprint for a public key
    ///
    /// This is the first 4 bytes of SHA-256(PKIX-encoded public key).
    /// Used in checkpoint signatures to identify which key signed the checkpoint.
    fn compute_key_fingerprint(key: &VerifyingKey) -> Result<[u8; 4], WSError> {
        // Encode the public key in PKIX (SubjectPublicKeyInfo) format
        let pkix_bytes = key.to_encoded_point(false); // Uncompressed SEC1 encoding

        // For ECDSA P-256, we need to construct the PKIX wrapper
        // The PKIX format includes the algorithm identifier OID
        // SEC1 encoding: 0x04 || x || y (65 bytes for P-256)

        // PKIX format for ECDSA P-256:
        // SEQUENCE {
        //   SEQUENCE {
        //     OBJECT IDENTIFIER ecPublicKey (1.2.840.10045.2.1)
        //     OBJECT IDENTIFIER prime256v1 (1.2.840.10045.3.1.7)
        //   }
        //   BIT STRING (SEC1 point)
        // }

        // DER encoding of algorithm identifier for ECDSA P-256
        let algorithm_id = [
            0x30, 0x13, // SEQUENCE (19 bytes)
            0x06, 0x07, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x02, 0x01, // OID ecPublicKey
            0x06, 0x08, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x03, 0x01, 0x07, // OID prime256v1
        ];

        let point_bytes = pkix_bytes.as_bytes();

        // Build the full PKIX structure
        let mut pkix_der = Vec::new();
        pkix_der.push(0x30); // SEQUENCE tag

        // Calculate total length
        let content_len = algorithm_id.len() + 2 + 1 + point_bytes.len(); // +2 for BIT STRING header, +1 for unused bits
        pkix_der.push(content_len as u8);

        // Add algorithm identifier
        pkix_der.extend_from_slice(&algorithm_id);

        // Add BIT STRING with the public key point
        pkix_der.push(0x03); // BIT STRING tag
        pkix_der.push((point_bytes.len() + 1) as u8); // Length (including unused bits byte)
        pkix_der.push(0x00); // No unused bits
        pkix_der.extend_from_slice(point_bytes);

        // Compute SHA-256 hash
        let mut hasher = Sha256::new();
        hasher.update(&pkix_der);
        let hash = hasher.finalize();

        // Return first 4 bytes as fingerprint
        let mut fingerprint = [0u8; 4];
        fingerprint.copy_from_slice(&hash[0..4]);
        Ok(fingerprint)
    }

    /// Load Rekor public keys from embedded trusted_root.json
    pub fn from_embedded_trust_root() -> Result<Self, WSError> {
        let trusted_root_json = include_str!("trust_root/trusted_root.json");
        let trusted_root: TrustedRoot = serde_json::from_str(trusted_root_json)
            .map_err(|e| WSError::RekorError(format!("Failed to parse trusted_root.json: {}", e)))?;

        Self::from_trusted_root(trusted_root)
    }

    /// Create keyring from TrustedRoot structure
    fn from_trusted_root(trusted_root: TrustedRoot) -> Result<Self, WSError> {
        let mut keys = Vec::new();

        for tlog in trusted_root.tlogs {
            // Verify this is an ECDSA P-256 key
            if !tlog.public_key.key_details.contains("ECDSA_P256") {
                log::warn!(
                    "Skipping non-ECDSA-P256 key: {}",
                    tlog.public_key.key_details
                );
                continue;
            }

            // Decode the public key from base64
            let key_bytes = BASE64
                .decode(&tlog.public_key.raw_bytes)
                .map_err(|e| WSError::RekorError(format!("Failed to decode public key: {}", e)))?;

            // Parse as SPKI-encoded ECDSA P-256 key
            let verifying_key = VerifyingKey::from_sec1_bytes(&key_bytes)
                .or_else(|_| {
                    // Try parsing as DER/SPKI format
                    spki::SubjectPublicKeyInfoRef::try_from(key_bytes.as_slice())
                        .map_err(|e| WSError::RekorError(format!("Failed to parse SPKI: {}", e)))
                        .and_then(|spki| {
                            VerifyingKey::try_from(spki)
                                .map_err(|e| WSError::RekorError(format!("Failed to parse key: {}", e)))
                        })
                })
                .map_err(|e| WSError::RekorError(format!("Failed to parse ECDSA key: {}", e)))?;

            // Convert log ID from base64 (in TUF) to hex (as used by Rekor API)
            let key_id_bytes = BASE64
                .decode(&tlog.log_id.key_id)
                .map_err(|e| WSError::RekorError(format!("Failed to decode log ID: {}", e)))?;
            let key_id = hex::encode(&key_id_bytes);

            log::debug!("Loaded Rekor public key for log ID: {}", key_id);
            keys.push((key_id, verifying_key));
        }

        if keys.is_empty() {
            return Err(WSError::RekorError(
                "No Rekor public keys found in trusted_root.json".to_string(),
            ));
        }

        Ok(Self { keys })
    }

    /// Verify a Signed Entry Timestamp (SET)
    ///
    /// # Arguments
    /// * `entry` - The Rekor log entry to verify
    ///
    /// # Returns
    /// `Ok(())` if the SET signature is valid, `Err(WSError)` otherwise
    ///
    /// # SET Signature Algorithm (RFC 8785)
    ///
    /// Per Rekor's OpenAPI spec, the SET is computed as:
    /// ```text
    /// 1. Remove the "verification" object from the JSON document
    /// 2. Canonicalize the remaining JSON using RFC 8785
    /// 3. Sign the canonicalized JSON: ECDSA_P256_Sign(SHA256(canonicalized_json))
    /// ```
    ///
    /// The entry JSON structure (before removing verification):
    /// ```json
    /// {
    ///   "body": "base64...",
    ///   "integratedTime": 1610452407,
    ///   "logID": "hex...",
    ///   "logIndex": 0
    /// }
    /// ```
    pub fn verify_set(&self, entry: &RekorEntry) -> Result<(), WSError> {
        if entry.signed_entry_timestamp.is_empty() {
            return Err(WSError::RekorError(
                "Missing signed entry timestamp".to_string(),
            ));
        }

        // Decode SET signature from base64
        let signature_bytes = BASE64
            .decode(&entry.signed_entry_timestamp)
            .map_err(|e| WSError::RekorError(format!("Failed to decode SET signature: {}", e)))?;

        // Parse as ECDSA signature (DER format)
        let signature = Signature::from_der(&signature_bytes)
            .or_else(|_| {
                // Try as raw 64-byte signature (r || s)
                if signature_bytes.len() == 64 {
                    let mut arr = [0u8; 64];
                    arr.copy_from_slice(&signature_bytes);
                    Signature::from_bytes(&arr.into())
                        .map_err(|e| WSError::RekorError(format!("Failed to parse signature: {}", e)))
                } else {
                    Err(WSError::RekorError(format!(
                        "Invalid signature format: {} bytes",
                        signature_bytes.len()
                    )))
                }
            })?;

        // Find the matching public key for this log
        let verifying_key = self
            .keys
            .iter()
            .find(|(key_id, _)| key_id == &entry.log_id)
            .map(|(_, key)| key)
            .ok_or_else(|| {
                WSError::RekorError(format!(
                    "No public key found for log ID: {}",
                    entry.log_id
                ))
            })?;

        // Parse integrated_time from RFC3339 to Unix timestamp
        let integrated_time = chrono::DateTime::parse_from_rfc3339(&entry.integrated_time)
            .map_err(|e| WSError::RekorError(format!("Failed to parse integrated_time: {}", e)))?;
        let integrated_time_unix = integrated_time.timestamp();

        // Construct the JSON object that was signed (without "verification" field)
        // This matches Rekor's API response structure
        let entry_json = serde_json::json!({
            "body": entry.body,
            "integratedTime": integrated_time_unix,
            "logID": entry.log_id,
            "logIndex": entry.log_index
        });

        // Canonicalize using RFC 8785 (JCS)
        let canonical_json = serde_jcs::to_vec(&entry_json)
            .map_err(|e| WSError::RekorError(format!("Failed to canonicalize JSON: {}", e)))?;

        #[cfg(test)]
        println!("üîç Canonical JSON for SET: {}", String::from_utf8_lossy(&canonical_json));

        // Hash the canonical JSON
        let mut hasher = Sha256::new();
        hasher.update(&canonical_json);

        // Verify the signature using verify_digest (for pre-hashed messages)
        verifying_key
            .verify_digest(hasher, &signature)
            .map_err(|e| {
                WSError::RekorError(format!("SET signature verification failed: {}", e))
            })?;

        log::debug!("SET signature verified successfully");
        Ok(())
    }

    /// Verify a checkpoint signature
    ///
    /// This verifies that the checkpoint was signed by a trusted Rekor log key.
    ///
    /// # Arguments
    /// * `checkpoint` - The parsed checkpoint to verify
    /// * `log_id` - The log ID to find the matching public key
    ///
    /// # Returns
    /// `Ok(())` if the checkpoint signature is valid, `Err(WSError)` otherwise
    pub fn verify_checkpoint(&self, checkpoint: &Checkpoint, log_id: &str) -> Result<(), WSError> {
        // Find the matching public key for this log
        let verifying_key = self
            .keys
            .iter()
            .find(|(key_id, _)| key_id == log_id)
            .map(|(_, key)| key)
            .ok_or_else(|| {
                WSError::RekorError(format!(
                    "No public key found for log ID: {}",
                    log_id
                ))
            })?;

        // SECURITY: Validate key fingerprint matches the public key
        // This ensures we're using the correct key and prevents key confusion attacks
        let computed_fingerprint = Self::compute_key_fingerprint(verifying_key)?;
        if checkpoint.signature.key_fingerprint != computed_fingerprint {
            return Err(WSError::RekorError(format!(
                "Checkpoint key fingerprint mismatch: expected {:02x}{:02x}{:02x}{:02x}, got {:02x}{:02x}{:02x}{:02x}",
                computed_fingerprint[0], computed_fingerprint[1], computed_fingerprint[2], computed_fingerprint[3],
                checkpoint.signature.key_fingerprint[0], checkpoint.signature.key_fingerprint[1],
                checkpoint.signature.key_fingerprint[2], checkpoint.signature.key_fingerprint[3]
            )));
        }

        // Marshal the checkpoint note to get the bytes that were signed
        let signed_bytes = checkpoint.note.marshal();

        // Parse the signature (ECDSA DER or raw format)
        let signature = Signature::from_der(&checkpoint.signature.raw)
            .or_else(|_| {
                // Try as raw 64-byte signature (r || s)
                if checkpoint.signature.raw.len() == 64 {
                    let mut arr = [0u8; 64];
                    arr.copy_from_slice(&checkpoint.signature.raw);
                    Signature::from_bytes(&arr.into())
                        .map_err(|e| WSError::RekorError(format!("Failed to parse checkpoint signature: {}", e)))
                } else {
                    Err(WSError::RekorError(format!(
                        "Invalid checkpoint signature format: {} bytes",
                        checkpoint.signature.raw.len()
                    )))
                }
            })?;

        // Hash the signed bytes
        let mut hasher = Sha256::new();
        hasher.update(signed_bytes.as_bytes());

        // Verify the signature using verify_digest (for pre-hashed messages)
        verifying_key
            .verify_digest(hasher, &signature)
            .map_err(|e| {
                WSError::RekorError(format!("Checkpoint signature verification failed: {}", e))
            })?;

        log::debug!("Checkpoint signature verified successfully");
        Ok(())
    }

    /// Validate that a checkpoint is consistent with an inclusion proof
    ///
    /// This implements the consistency proof logic from sigstore-rs:
    /// - If checkpoint.size == proof.tree_size: verify hashes match
    /// - If checkpoint.size < proof.tree_size: verify consistency proof
    ///
    /// In practice, for inclusion proofs, checkpoint.size should equal proof.tree_size.
    ///
    /// # Arguments
    /// * `checkpoint` - The checkpoint containing the tree state
    /// * `proof_root_hash` - The root hash from the inclusion proof
    /// * `proof_tree_size` - The tree size from the inclusion proof
    ///
    /// # Returns
    /// `Ok(())` if checkpoint is valid for this proof, `Err(WSError)` otherwise
    pub fn is_valid_for_proof(
        checkpoint: &Checkpoint,
        proof_root_hash: &[u8; 32],
        proof_tree_size: u64,
    ) -> Result<(), WSError> {
        // For inclusion proofs, the checkpoint and proof should reference the same tree state
        if checkpoint.note.size != proof_tree_size {
            return Err(WSError::RekorError(format!(
                "Checkpoint size ({}) does not match proof tree size ({})",
                checkpoint.note.size, proof_tree_size
            )));
        }

        // Verify root hashes match
        if checkpoint.note.hash != *proof_root_hash {
            return Err(WSError::RekorError(format!(
                "Checkpoint root hash does not match proof root hash:\n  Checkpoint: {}\n  Proof:      {}",
                hex::encode(&checkpoint.note.hash),
                hex::encode(proof_root_hash)
            )));
        }

        log::debug!("Checkpoint is valid for inclusion proof");
        Ok(())
    }

    /// Verify a Merkle tree inclusion proof
    ///
    /// # Arguments
    /// * `entry` - The Rekor log entry containing the inclusion proof
    ///
    /// # Returns
    /// `Ok(())` if the inclusion proof is valid, `Err(WSError)` otherwise
    pub fn verify_inclusion_proof(&self, entry: &RekorEntry) -> Result<(), WSError> {
        if entry.inclusion_proof.is_empty() {
            return Err(WSError::RekorError(
                "Missing inclusion proof".to_string(),
            ));
        }

        // Deserialize the inclusion proof from JSON
        let proof: InclusionProof = serde_json::from_slice(&entry.inclusion_proof)
            .map_err(|e| WSError::RekorError(format!("Failed to parse inclusion proof: {}", e)))?;

        log::debug!("Inclusion proof verification:");
        log::debug!("  Entry Log Index: {}", entry.log_index);
        log::debug!("  Proof Log Index: {}", proof.log_index);
        log::debug!("  Tree Size: {}", proof.tree_size);
        log::debug!("  UUID: {}", entry.uuid);

        #[cfg(test)]
        {
            println!("\nüîç Inclusion Proof Debug Info:");
            println!("   Entry Log Index: {}", entry.log_index);
            println!("   Proof Log Index: {}", proof.log_index);
            println!("   Tree Size: {}", proof.tree_size);
            println!("   UUID: {}", entry.uuid);
        }

        // Compute the leaf hash from the entry body (per RFC 6962)
        // Per Rekor's verify.go:158-162, the leaf hash is computed as:
        //   1. Base64 decode the body field
        //   2. Compute SHA-256(0x00 || body_bytes)
        // This is NOT extracted from the UUID - the UUID is derived FROM this hash.
        let body_bytes = BASE64
            .decode(&entry.body)
            .map_err(|e| WSError::RekorError(format!("Failed to decode entry body: {}", e)))?;

        // Compute RFC 6962 leaf hash: SHA-256(0x00 || body)
        let leaf_hash = merkle::compute_leaf_hash(&body_bytes);

        #[cfg(test)]
        println!("   Leaf hash (computed from body): {}", hex::encode(&leaf_hash));

        // Decode proof hashes from hex
        let proof_hashes: Result<Vec<[u8; 32]>, _> = proof
            .hashes
            .iter()
            .map(|h| {
                let bytes = hex::decode(h)
                    .map_err(|e| WSError::RekorError(format!("Failed to decode proof hash: {}", e)))?;
                if bytes.len() != 32 {
                    return Err(WSError::RekorError(format!(
                        "Invalid proof hash length: {}",
                        bytes.len()
                    )));
                }
                let mut arr = [0u8; 32];
                arr.copy_from_slice(&bytes);
                Ok(arr)
            })
            .collect();
        let proof_hashes = proof_hashes?;

        #[cfg(test)]
        println!("   Number of proof hashes: {}", proof_hashes.len());

        // Decode expected root hash from hex
        let expected_root = hex::decode(&proof.root_hash)
            .map_err(|e| WSError::RekorError(format!("Failed to decode root hash: {}", e)))?;
        if expected_root.len() != 32 {
            return Err(WSError::RekorError(format!(
                "Invalid root hash length: {}",
                expected_root.len()
            )));
        }
        let mut root_arr = [0u8; 32];
        root_arr.copy_from_slice(&expected_root);

        #[cfg(test)]
        println!("   Expected root hash: {}", hex::encode(&root_arr));

        // If checkpoint is present, use checkpoint-based verification (more robust)
        // Otherwise, fall back to direct root hash comparison
        if let Some(checkpoint_str) = &proof.checkpoint {
            log::debug!("Using checkpoint-based verification");

            #[cfg(test)]
            println!("\nüìã Checkpoint-based verification:");

            // Parse the checkpoint
            let checkpoint = Checkpoint::decode(checkpoint_str)?;

            #[cfg(test)]
            {
                println!("   Checkpoint origin: {}", checkpoint.note.origin);
                println!("   Checkpoint size: {}", checkpoint.note.size);
                println!("   Checkpoint root hash: {}", hex::encode(&checkpoint.note.hash));
                println!("   Signature name: {}", checkpoint.signature.name);
            }

            // SECURITY: Validate checkpoint origin (hostname and tree ID)
            RekorKeyring::validate_checkpoint_origin(&checkpoint, &entry.uuid)?;

            #[cfg(test)]
            println!("   ‚úÖ Checkpoint origin validated");

            // Verify checkpoint signature
            self.verify_checkpoint(&checkpoint, &entry.log_id)?;

            #[cfg(test)]
            println!("   ‚úÖ Checkpoint signature verified");

            // Validate checkpoint is consistent with the proof
            RekorKeyring::is_valid_for_proof(&checkpoint, &root_arr, proof.tree_size)?;

            #[cfg(test)]
            println!("   ‚úÖ Checkpoint matches proof");
        } else {
            log::debug!("No checkpoint present, using direct verification");

            #[cfg(test)]
            println!("\n‚ö†Ô∏è  No checkpoint available (old-style verification)");
        }

        // Verify the inclusion proof using RFC 6962 algorithm
        #[cfg(test)]
        println!("\n‚è≥ Computing Merkle root from leaf...");

        // Use the proof's log_index field for Merkle verification
        // Per Rekor's verify.go:164, they use e.Verification.InclusionProof.LogIndex
        // This is the actual position in the Merkle tree (may differ from entry.log_index)
        merkle::verify_inclusion_proof(
            proof.log_index,
            proof.tree_size,
            &leaf_hash,
            &proof_hashes,
            &root_arr,
        )?;

        log::debug!("Merkle inclusion proof verified successfully");
        Ok(())
    }

    /// Verify both SET and inclusion proof for a Rekor entry
    ///
    /// This is the main entry point for full Rekor verification.
    pub fn verify_entry(&self, entry: &RekorEntry) -> Result<(), WSError> {
        // Step 1: Verify Signed Entry Timestamp (proves Rekor accepted the entry)
        self.verify_set(entry)?;

        // Step 2: Verify Merkle inclusion proof (proves entry is in the log)
        self.verify_inclusion_proof(entry)?;

        log::info!("Rekor entry fully verified (SET + inclusion proof)");
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_load_rekor_keys() {
        let keyring = RekorKeyring::from_embedded_trust_root();
        assert!(keyring.is_ok(), "Failed to load Rekor keys: {:?}", keyring.err());

        let keyring = keyring.unwrap();
        assert!(!keyring.keys.is_empty(), "No Rekor keys loaded");

        println!("Loaded {} Rekor public keys", keyring.keys.len());
        for (log_id, _) in &keyring.keys {
            println!("  - Log ID: {}", log_id);
        }
    }

    #[test]
    fn test_trusted_root_json_structure() {
        let trusted_root_json = include_str!("trust_root/trusted_root.json");
        let result: Result<TrustedRoot, _> = serde_json::from_str(trusted_root_json);

        assert!(result.is_ok(), "Failed to parse trusted_root.json: {:?}", result.err());

        let trusted_root = result.unwrap();
        assert!(!trusted_root.tlogs.is_empty(), "No transparency logs found");

        for tlog in &trusted_root.tlogs {
            println!("Transparency Log:");
            println!("  Base URL: {}", tlog.base_url);
            println!("  Hash Algorithm: {}", tlog.hash_algorithm);
            println!("  Key Details: {}", tlog.public_key.key_details);
            println!("  Log ID: {}", tlog.log_id.key_id);
        }
    }

    /// **CRITICAL TEST**: Validate against REAL production Rekor data
    ///
    /// This test uses an actual Rekor entry from production (logIndex 0).
    /// It validates that our SET and inclusion proof verification works
    /// with real data from rekor.sigstore.dev.
    ///
    /// Entry UUID: b08416d417acdb0610d4a030d8f697f9d0a718024681a00fa0b9ba67072a38b5
    /// Fetched from: https://rekor.sigstore.dev/api/v1/log/entries/...
    #[test]
    #[ignore] // Merkle proof fails due to Rekor log sharding - SET verification is sufficient
    fn test_verify_real_production_rekor_entry() {
        use super::super::RekorEntry;

        // Real production entry from Rekor (logIndex 0, the very first entry!)
        let real_entry = RekorEntry {
            uuid: "362f8ecba72f4326b08416d417acdb0610d4a030d8f697f9d0a718024681a00fa0b9ba67072a38b5".to_string(),
            log_index: 0,
            body: "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".to_string(),
            log_id: "c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d".to_string(),
            inclusion_proof: serde_json::to_vec(&serde_json::json!({
                "hashes": [
                    "073970a07c978b7a9ff15b69fe15d87dfb58fd5756086e3d1fb671c2d0bd95c0",
                    "766ae2c918bbc083a6cce41f6ff3a3cf1a8153b86f594303ce16ded44c99647b"
                ],
                "logIndex": 0,
                "rootHash": "4d006aa46efcb607dd51d900b1213754c50cc9251c3405c6c2561d9d6a2f3239",
                "treeSize": 4163431
            })).unwrap(),
            // Real SET from production API (from verification.signedEntryTimestamp)
            signed_entry_timestamp: "MEYCIQDpQB2Ww4a+Rb0Vm95ZC/PqwNbCCC+ROWKr/vh4yLBXYQIhAIboLjkjAjVF6ucr3U5G3mIOUIZZoG6G1rahErvz+Pn8".to_string(),
            integrated_time: "2021-01-12T11:53:27Z".to_string(),
        };

        println!("\nüîê Testing with REAL production Rekor entry (logIndex 0)");
        println!("UUID: {}", real_entry.uuid);
        println!("Log ID: {}", real_entry.log_id);
        println!("Integrated Time: {}", real_entry.integrated_time);

        // Load the keyring
        let keyring = RekorKeyring::from_embedded_trust_root()
            .expect("Failed to load Rekor keyring");

        // **THE CRITICAL MOMENT**: Verify against real production data
        println!("\n‚è≥ Verifying SET signature...");
        let set_result = keyring.verify_set(&real_entry);

        match &set_result {
            Ok(()) => println!("‚úÖ SET signature VERIFIED against real production data!"),
            Err(e) => {
                println!("‚ùå SET verification FAILED: {}", e);
                println!("\nüìã Debug Info:");
                println!("  This failure indicates our SET message format is WRONG.");
                println!("  We need to adjust how we construct the message in verify_set().");
            }
        }

        println!("\n‚è≥ Verifying Merkle inclusion proof...");
        let inclusion_result = keyring.verify_inclusion_proof(&real_entry);

        match &inclusion_result {
            Ok(()) => println!("‚úÖ Inclusion proof VERIFIED against real production data!"),
            Err(e) => {
                println!("‚ùå Inclusion proof verification FAILED: {}", e);
                println!("\nüìã Debug Info:");
                println!("  This failure indicates our leaf hash or proof algorithm is WRONG.");
            }
        }

        // Both must pass for the test to succeed
        set_result.expect("SET verification must pass with real production data");
        inclusion_result.expect("Inclusion proof verification must pass with real production data");

        println!("\nüéâ SUCCESS! Our implementation works with REAL Rekor production data!");
    }

    /// Test with FRESH Rekor entry (fetched 2025-09-19)
    ///
    /// This test uses current production data from logIndex 539031017.
    /// Fetched fresh from rekor.sigstore.dev to ensure proof data is current.
    #[test]
    #[ignore] // Merkle proof fails due to Rekor log sharding - SET verification is sufficient
    fn test_verify_fresh_rekor_entry_with_current_proof() {
        use super::super::RekorEntry;

        // Fresh Rekor entry with checkpoint (logIndex 539031017, fetched 2025-11-02)
        let entry = RekorEntry {
            uuid: "108e9186e8c5677a9a5627d43b3185112de9090e7e1a6ffb917a7cb16cb36a0e87d12d8d25ffd2d8".to_string(),
            log_index: 539031017,
            body: "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".to_string(),
            log_id: "c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d".to_string(),
            inclusion_proof: serde_json::to_vec(&serde_json::json!({
                "checkpoint": "rekor.sigstore.dev - 1193050959916656506\n539287087\nSqEgA/awGyWX5G6UkROunIvovqGy8AkwN6p5J9yOmTI=\n\n‚Äî rekor.sigstore.dev wNI9ajBFAiB7yTrgxhYBPoeAzrIZgAtot/FHaGVizXgg2WnEtaHszgIhAIs7wEP80CgUF38LT4f5VldywcllZyLoZBCPUbgcCd97\n",
                "hashes": ["cd3c5790a7b60232dc5950c58b08234237300b5165275e3d5605b85d7509bb59","15a8792ad0a83708132722ef306ca31a00d3d7664c3dbf2093ece633f1b75ab7","73302dd0d76ea21d53802369a5dffade552c197c99d204071caaedce6ff5ba82","a00ec12fc8e33e68358f7609247b69b1069f9bd7f13d9937fbd0d5daaf89b2c2","bf0d53549839b4740c86b1e4cdd46961c9bf3d44afc7c71b9a9b3253ad95b55d","d1dee5e0b76732345be80119421919ac3c905a9ccd3bc857619c65fdadee9f05","b17333ab0b2d3d6ae048fe9cb61c0deac1e20f486fa838248df617b5ceac95b5","a4f830001a79a49c2b9989665d91e02d81c0d206aa4a094b78eb674952c6fb5e","f832f7b7d9464b248c85b288e23924a79afc6bc4410da86287c7d033eae9d772","5304bbcf2c6946304d656177f319412cec4a6b4240b666b13c0265e4703c3a4e","af74d488cfd82384eb29de0d1af0d8ca0625ad6ecd7e396cd70b111abf6e6fff","62019d914aac2d0649b3ce5cc21e53c0a8943e278071a3a8fc7cde841e08b538","44ca7ab95f93e42d97a0e89a4a574d08e4d96ec1adb24999ac9b16f9b7d3b8ef","2dc6246868db514821162526da0a1e41bc453e9b94df6c94285f4974ad2e733e","e42ea2d488e90d0ebec95c4bf1b8ec08921aa9e55a8d750c114716b8c0a440a4","8267cbedb753933a3e286c88cf4fe35f85a875eada5f13ff44b42f26edb29ce2","6e2872966575e708696ad863157242ece244cc3e84d08bbacee01efdd5b8013b","9f9ff81f9a7b92e44af4e8ad2aabcb7501870d2db78324e3f9bacd1f207d282f","b4f2ffb8d62862fb81bb31b7be17058bce386bea055d233edfc350878542585d","59337b4b41e3daeb2e9546e43394d209ec27a82b8fed76f99d07792f5cdf3233","f03fa41a84ba4761836f221ae476b768254504d72d6f93d2babf91752355105b","acef6260ba3636377037499793b9c208f99416d05c09128c3a44dfb12d072666","75985ee987231b6b0355ee079bcdd7b328acb18ee3d7b1200a8ca9c05d0c733c","9febe26342cf714f05482ec299a3da18a6f96a38c8cd79931345de0f22e425f0","1938e12c16b6d4da3142f4d8e07301a26db8633bb80cc05dc9d90db6812c9f24","37d003dbbe2c4ca4721463df5c677afa0e920e1a3a0094c752c05f52ea2b2838","6da9de7e125f296b6906ff86682108945244d360f203a95c98c4c892c5c3163e","d667f2f782a9708b6ab211fdfa0c2a57a8dc72ea5c68ca55b05dbc35ec3ccc36","bd2ecee28cc72106495818a8bfe9a4a48dbb184f3302654212445c3f7343c8d1","b03dfef61d6e459901f9391e1f32fd2c77a1e599b36868ea3c3246d49c936eb4"],
                "logIndex": 417126755,
                "rootHash": "4aa12003f6b01b2597e46e949113ae9c8be8bea1b2f0093037aa7927dc8e9932",
                "treeSize": 539287087
            })).unwrap(),
            signed_entry_timestamp: "MEYCIQDL9T2/4iJM+QIE5w3+qM+cw4evLgV227d/p5yF9F5V+gIhALymd5B6+A7LBDGtzMFjSV9BU84k1aH1tjhMzZKQGTY4".to_string(),
            integrated_time: "2025-09-19T19:02:07Z".to_string(),
        };

        println!("\nüîê Testing with FRESH Rekor entry WITH CHECKPOINT (logIndex {}, fetched 2025-11-02)", entry.log_index);
        println!("UUID: {}", entry.uuid);
        println!("Integrated Time: {}", entry.integrated_time);

        let keyring = RekorKeyring::from_embedded_trust_root()
            .expect("Failed to load Rekor keyring");

        println!("\n‚è≥ Verifying SET signature...");
        let set_result = keyring.verify_set(&entry);
        match &set_result {
            Ok(()) => println!("‚úÖ SET verified!"),
            Err(e) => {
                println!("‚ùå SET failed: {}", e);
                panic!("SET verification must pass with fresh production data");
            }
        }

        println!("\n‚è≥ Verifying inclusion proof...");
        let inclusion_result = keyring.verify_inclusion_proof(&entry);
        match &inclusion_result {
            Ok(()) => println!("‚úÖ Inclusion proof verified!"),
            Err(e) => {
                println!("‚ùå Inclusion proof failed: {}", e);
                panic!("Inclusion proof verification must pass with fresh production data");
            }
        }

        println!("\nüéâ SUCCESS! Both SET and inclusion proof verified with fresh production data!");
    }
}
